{"cells":[{"cell_type":"markdown","metadata":{"id":"o8ag4YWyUscg"},"source":["# Natural Language Processing using NLTK"]},{"cell_type":"markdown","metadata":{"id":"Br1K0f51Uscn"},"source":["# Install NLTK"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKRnOYtxUscp","executionInfo":{"status":"ok","timestamp":1749311329994,"user_tz":-210,"elapsed":2709,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"5b9a0370-33fe-4a81-fa37-a696812e6719"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}],"source":["!pip install nltk"]},{"cell_type":"markdown","metadata":{"id":"Z_SW97BmUscu"},"source":["# Download nltk"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9N7kvBwoUscw","executionInfo":{"status":"ok","timestamp":1749311329994,"user_tz":-210,"elapsed":6,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":["# import nltk\n","# nltk.download()"]},{"cell_type":"markdown","metadata":{"id":"ne-P7c9jUscz"},"source":["# import library"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"lzowYI1LUsc0","executionInfo":{"status":"ok","timestamp":1749311329995,"user_tz":-210,"elapsed":6,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":["import nltk"]},{"cell_type":"markdown","metadata":{"id":"jeZGEFkMUsc2"},"source":["## Open text"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZxuPj8wE3yz","executionInfo":{"status":"ok","timestamp":1749311332098,"user_tz":-210,"elapsed":2109,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"12358f11-764a-4b4d-d0e3-db6301b4e0db"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZ5aMYTzUsc4","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":607,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"a880b510-0b66-483d-d66e-43048b3c468f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\n"]}],"source":["file = open(\"/content/drive/MyDrive/Colab Notebooks/nlp/openfile.txt\",encoding=\"utf-8\")\n","text=file.read()\n","print(text)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3wfc8ufUsc6","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":72,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"24338cd3-0aca-4883-b1fb-31cb5a60acca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\n"]}],"source":["with open('/content/drive/MyDrive/Colab Notebooks/nlp/openfile.txt','r') as f:\n","    text=f.read()\n","    print(text)"]},{"cell_type":"markdown","metadata":{"id":"IqTqkBUYUsc7"},"source":["# Sentence Tokenize"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YomBs37Usc8","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":29,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"42d5b33c-a5ee-47f7-9a30-579a2c1d1603"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Natural language processing is a subfield of linguistics, computer science, and artificial intelligence.', 'NLP concerned with the interactions between computers and human languages.', 'In particular how to program computers to process and analyze large amounts of natural language data.']\n"]}],"source":["paragraph = \"\"\"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence.\n","                NLP concerned with the interactions between computers and human languages.\n","                In particular how to program computers to process and analyze large amounts of natural language data.\"\"\"\n","\n","# Tokenizing words\n","from nltk.tokenize import sent_tokenize\n","words = nltk.sent_tokenize(paragraph)\n","print(words)"]},{"cell_type":"markdown","metadata":{"id":"qPUv4wKYUsc9"},"source":["# Word Tokenize"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46f16LBWUsc-","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":20,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"dcecc0b9-2877-4b83-b565-f189714713a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Natural', 'language', 'processing', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'NLP', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'languages', '.', 'In', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"]}],"source":["paragraph = \"\"\"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence.\n","                NLP concerned with the interactions between computers and human languages.\n","                In particular how to program computers to process and analyze large amounts of natural language data.\"\"\"\n","\n","# Tokenizing words\n","from nltk.tokenize import word_tokenize\n","words = nltk.word_tokenize(paragraph)\n","print(words)"]},{"cell_type":"markdown","metadata":{"id":"hYEs-XlBUsc_"},"source":["# PorterStemmer"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"AwgN9dNIUsc_","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":14,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":["import nltk\n","from nltk.stem import PorterStemmer"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g67-_kzhUsdA","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":13,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"6e88609f-f259-4978-f3e7-e45d2a07ae76"},"outputs":[{"output_type":"stream","name":"stdout","text":["natur languag process is a subfield of linguist , comput scienc , and artifici intellig .\n","nlp concern with the interact between comput and human languag .\n","in particular how to program comput to process and analyz larg amount of natur languag data .\n"]}],"source":["sentences = nltk.sent_tokenize(paragraph)\n","stemmer = PorterStemmer()\n","\n","# Stemming\n","for i in range(len(sentences)):\n","    words = nltk.word_tokenize(sentences[i])\n","    words = [stemmer.stem(word) for word in words]\n","    sentences[i] = ' '.join(words)\n","    print(sentences[i])\n"]},{"cell_type":"markdown","metadata":{"id":"C0XwPQ9bUsdB"},"source":["# Lemmatization"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-OkgtNHcUsdC","executionInfo":{"status":"ok","timestamp":1749311332687,"user_tz":-210,"elapsed":3,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":["import nltk\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJmvafDwUsdC","executionInfo":{"status":"ok","timestamp":1749311337011,"user_tz":-210,"elapsed":4327,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"8f315e40-e399-47c1-b058-c82e4c5f59b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Natural language processing is a subfield of linguistics , computer science , and artificial intelligence .\n","NLP concerned with the interaction between computer and human language .\n","In particular how to program computer to process and analyze large amount of natural language data .\n"]}],"source":["sentences = nltk.sent_tokenize(paragraph)\n","lemmatizer = WordNetLemmatizer()\n","\n","# Lemmatization\n","for i in range(len(sentences)):\n","    words = nltk.word_tokenize(sentences[i])\n","    words = [lemmatizer.lemmatize(word) for word in words]\n","    sentences[i] = ' '.join(words)\n","    print(sentences[i])"]},{"cell_type":"markdown","metadata":{"id":"3AeRQc-NUsdD"},"source":["# Remove Stopword"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRxqKpS2UsdD","executionInfo":{"status":"ok","timestamp":1749311337011,"user_tz":-210,"elapsed":96,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"df73ffe7-12fa-43dc-ee32-b64ee7c7869e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uL8Rt4-UsdE","executionInfo":{"status":"ok","timestamp":1749311337011,"user_tz":-210,"elapsed":81,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"58e1563d-bc5e-400a-c704-b0ab1bfe1e0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Natural language processing subfield linguistics , computer science , artificial intelligence .\n","NLP concerned interactions computers human languages .\n","In particular program computers process analyze large amounts natural language data .\n"]}],"source":["sentences = nltk.sent_tokenize(paragraph)\n","\n","# Removing stopwords\n","for i in range(len(sentences)):\n","    words = nltk.word_tokenize(sentences[i])\n","    words = [word for word in words if word not in stopwords.words('english')]\n","    sentences[i] = ' '.join(words)\n","    print(sentences[i])"]},{"cell_type":"code","execution_count":23,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"WHX_jwBxUsdF","executionInfo":{"status":"ok","timestamp":1749311337011,"user_tz":-210,"elapsed":64,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"85197581-afae-4dc3-84e4-3f8bc393dc2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"]}],"source":["print(stopwords.words('english'))"]},{"cell_type":"markdown","metadata":{"id":"2qyHYkLjUsdL"},"source":["# POS Tagging"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtkjVFjZUsdM","executionInfo":{"status":"ok","timestamp":1749311337012,"user_tz":-210,"elapsed":46,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"a03e64ff-0f09-45e2-aa04-c9f43a62f5c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.'), ('NLP', 'NNP'), ('concerned', 'VBD'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('languages', 'NNS'), ('.', '.'), ('In', 'IN'), ('particular', 'JJ'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('computers', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n"]}],"source":["# Part Of Speech Tagging\n","words = nltk.word_tokenize(paragraph)\n","\n","tagged_words = nltk.pos_tag(words)\n","print(tagged_words)"]},{"cell_type":"markdown","metadata":{"id":"umANb1LHUsdN"},"source":["# Named Entity Recognition"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuXsirL_UsdO","executionInfo":{"status":"ok","timestamp":1749311337012,"user_tz":-210,"elapsed":16,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"98c84945-4eec-4ec5-ba3f-3076214b5d85"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('i', 'NN'), ('go', 'VBP'), ('home', 'NN')]\n"]}],"source":["# POS Tagging\n","paragraph=\"i go home\"\n","words = nltk.word_tokenize(paragraph)\n","\n","tagged_words = nltk.pos_tag(words)\n","print(tagged_words)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzZvMaMqUsdO","executionInfo":{"status":"ok","timestamp":1749311449642,"user_tz":-210,"elapsed":425,"user":{"displayName":"Star","userId":"16069218276966640711"}},"outputId":"e8dc7fa3-48a9-446a-f38e-d9f8b4eae6e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["       S           \n","  _____|_______     \n","i/NN go/VBP home/NN\n","\n"]}],"source":["# Named entity recognition\n","namedEnt = nltk.ne_chunk(tagged_words)\n","from nltk.tree import Tree\n","Tree.fromstring(str(namedEnt)).pretty_print()\n","\n","# namedEnt.draw()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pnnWK-w4UsdP","executionInfo":{"status":"aborted","timestamp":1749311337349,"user_tz":-210,"elapsed":11,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xw48r397UsdQ","executionInfo":{"status":"aborted","timestamp":1749311337350,"user_tz":-210,"elapsed":12,"user":{"displayName":"Star","userId":"16069218276966640711"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}